{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee731d2d",
   "metadata": {},
   "source": [
    "# üöÄ Basic Federated Learning Experiment\n",
    "\n",
    "This notebook will guide you through running your first federated learning experiment using our framework. You'll learn how to:\n",
    "\n",
    "- Set up a basic FL experiment\n",
    "- Configure clients and server\n",
    "- Run training with different strategies\n",
    "- Monitor and analyze results\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "Make sure you've completed the introduction notebook and have all dependencies installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add framework to path\n",
    "framework_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(framework_root))\n",
    "\n",
    "print(f\"Framework root: {framework_root}\")\n",
    "print(f\"Current working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef6b7ce",
   "metadata": {},
   "source": [
    "## üîß Experiment Configuration\n",
    "\n",
    "Let's start by configuring our first federated learning experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ecb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "config = {\n",
    "    'num_clients': 5,           # Number of federated clients\n",
    "    'num_rounds': 10,           # Number of federation rounds\n",
    "    'dataset': 'MNIST',         # Dataset to use (MNIST, FMNIST, CIFAR10)\n",
    "    'strategy': 'fedavg',       # Aggregation strategy\n",
    "    'attack': 'none'            # No attacks for this basic experiment\n",
    "}\n",
    "\n",
    "print(\"üéØ Experiment Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eaf434",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÇÔ∏è Method 1: Using the Automated Script\n",
    "\n",
    "The easiest way to run an experiment is using our automated script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic_experiment(config):\n",
    "    \"\"\"Run a basic federated learning experiment using the automated script.\"\"\"\n",
    "    \n",
    "    # Construct the command\n",
    "    script_path = framework_root / \"experiment_runners\" / \"run_with_attacks.py\"\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        str(script_path),\n",
    "        \"--num-clients\", str(config['num_clients']),\n",
    "        \"--rounds\", str(config['num_rounds']),\n",
    "        \"--dataset\", config['dataset'],\n",
    "        \"--strategy\", config['strategy'],\n",
    "        \"--attack\", config['attack']\n",
    "    ]\n",
    "    \n",
    "    print(f\"üöÄ Running command: {' '.join(cmd)}\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Starting Federated Learning Experiment...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Run the experiment\n",
    "    try:\n",
    "        # Change to the framework root directory\n",
    "        original_cwd = os.getcwd()\n",
    "        os.chdir(framework_root)\n",
    "        \n",
    "        # Run the experiment\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        \n",
    "        # Restore original directory\n",
    "        os.chdir(original_cwd)\n",
    "        \n",
    "        print(\"\\nüìä Experiment Output:\")\n",
    "        print(\"-\" * 30)\n",
    "        if result.stdout:\n",
    "            print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"Errors/Warnings:\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "        print(f\"\\n‚úÖ Experiment completed with return code: {result.returncode}\")\n",
    "        return result.returncode == 0\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è∞ Experiment timed out after 5 minutes\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running experiment: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the experiment\n",
    "success = run_basic_experiment(config)\n",
    "print(f\"\\nüéØ Experiment {'succeeded' if success else 'failed'}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0162371a",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Method 2: Manual Server and Client Setup\n",
    "\n",
    "For better understanding, let's also see how to run server and clients manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_server_process(config):\n",
    "    \"\"\"Start the federated learning server in a separate process.\"\"\"\n",
    "    server_path = framework_root / \"core\" / \"server.py\"\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        str(server_path),\n",
    "        \"--rounds\", str(config['num_rounds']),\n",
    "        \"--dataset\", config['dataset'],\n",
    "        \"--strategy\", config['strategy']\n",
    "    ]\n",
    "    \n",
    "    print(f\"üñ•Ô∏è Starting server with command: {' '.join(cmd)}\")\n",
    "    \n",
    "    # Change to framework directory and start server\n",
    "    original_cwd = os.getcwd()\n",
    "    os.chdir(framework_root)\n",
    "    \n",
    "    server_process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    os.chdir(original_cwd)\n",
    "    return server_process\n",
    "\n",
    "def start_client_process(client_id, config):\n",
    "    \"\"\"Start a federated learning client.\"\"\"\n",
    "    client_path = framework_root / \"core\" / \"client.py\"\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        str(client_path),\n",
    "        \"--cid\", str(client_id),\n",
    "        \"--dataset\", config['dataset']\n",
    "    ]\n",
    "    \n",
    "    print(f\"üë§ Starting client {client_id} with command: {' '.join(cmd)}\")\n",
    "    \n",
    "    # Change to framework directory and start client\n",
    "    original_cwd = os.getcwd()\n",
    "    os.chdir(framework_root)\n",
    "    \n",
    "    client_process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    os.chdir(original_cwd)\n",
    "    return client_process\n",
    "\n",
    "print(\"üîß Manual setup functions defined. Ready to run manual experiment if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5bcdd",
   "metadata": {},
   "source": [
    "## üìä Understanding the Experiment Flow\n",
    "\n",
    "Let's break down what happens during a federated learning experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_fl_process():\n",
    "    \"\"\"Explain the federated learning process step by step.\"\"\"\n",
    "    \n",
    "    print(\"üîÑ Federated Learning Process Overview:\\n\")\n",
    "    \n",
    "    steps = [\n",
    "        \"1. Server Initialization\",\n",
    "        \"   ‚Ä¢ Load initial model parameters\",\n",
    "        \"   ‚Ä¢ Initialize aggregation strategy\",\n",
    "        \"   ‚Ä¢ Start listening for client connections\",\n",
    "        \"\",\n",
    "        \"2. Client Connection\",\n",
    "        \"   ‚Ä¢ Clients connect to server\",\n",
    "        \"   ‚Ä¢ Load local datasets\",\n",
    "        \"   ‚Ä¢ Initialize local models\",\n",
    "        \"\",\n",
    "        \"3. Federation Round (repeated)\",\n",
    "        \"   ‚Ä¢ Server sends global model to selected clients\",\n",
    "        \"   ‚Ä¢ Clients perform local training\",\n",
    "        \"   ‚Ä¢ Clients send updates back to server\",\n",
    "        \"   ‚Ä¢ Server aggregates updates using chosen strategy\",\n",
    "        \"   ‚Ä¢ Server evaluates global model\",\n",
    "        \"\",\n",
    "        \"4. Completion\",\n",
    "        \"   ‚Ä¢ Final model evaluation\",\n",
    "        \"   ‚Ä¢ Results logging and cleanup\"\n",
    "    ]\n",
    "    \n",
    "    for step in steps:\n",
    "        print(step)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Key Concepts:\")\n",
    "    print(\"‚Ä¢ Local Training: Each client trains on its own data\")\n",
    "    print(\"‚Ä¢ Model Updates: Clients send parameter updates, not raw data\")\n",
    "    print(\"‚Ä¢ Aggregation: Server combines updates using chosen strategy\")\n",
    "    print(\"‚Ä¢ Privacy: Raw data never leaves the client\")\n",
    "\n",
    "explain_fl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068524ba",
   "metadata": {},
   "source": [
    "## üîç Monitoring and Analysis\n",
    "\n",
    "Let's check what results were generated and how to analyze them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_experiment_results():\n",
    "    \"\"\"Check for experiment results and logs.\"\"\"\n",
    "    \n",
    "    # Look for log files\n",
    "    log_files = []\n",
    "    for log_pattern in ['*.log', 'experiment_results/*', 'enhanced_experiment_results/*']:\n",
    "        log_files.extend(list(framework_root.glob(log_pattern)))\n",
    "    \n",
    "    print(\"üìÅ Found experiment files:\")\n",
    "    if log_files:\n",
    "        for log_file in log_files[:10]:  # Show first 10 files\n",
    "            file_size = log_file.stat().st_size if log_file.exists() else 0\n",
    "            print(f\"  ‚Ä¢ {log_file.name} ({file_size} bytes)\")\n",
    "        if len(log_files) > 10:\n",
    "            print(f\"  ... and {len(log_files) - 10} more files\")\n",
    "    else:\n",
    "        print(\"  No experiment files found yet.\")\n",
    "    \n",
    "    # Check for recent log entries\n",
    "    recent_logs = []\n",
    "    for log_file in framework_root.glob('*.log'):\n",
    "        if log_file.stat().st_size > 0:\n",
    "            recent_logs.append(log_file)\n",
    "    \n",
    "    if recent_logs:\n",
    "        print(f\"\\nüìã Recent activity in {len(recent_logs)} log files:\")\n",
    "        for log_file in recent_logs[:3]:  # Show first 3 log files\n",
    "            try:\n",
    "                with open(log_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    if lines:\n",
    "                        print(f\"\\n{log_file.name} (last few lines):\")\n",
    "                        for line in lines[-3:]:\n",
    "                            print(f\"  {line.strip()}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Could not read {log_file.name}: {e}\")\n",
    "\n",
    "check_experiment_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0ed09",
   "metadata": {},
   "source": [
    "## üéØ Comparing Different Strategies\n",
    "\n",
    "Let's run quick experiments with different aggregation strategies to see their behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc098f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_strategy_comparison():\n",
    "    \"\"\"Run quick experiments with different strategies for comparison.\"\"\"\n",
    "    \n",
    "    strategies = ['fedavg', 'fedprox', 'fedavgm']\n",
    "    results = {}\n",
    "    \n",
    "    print(\"üîÑ Running strategy comparison experiments...\")\n",
    "    print(\"(Using smaller configuration for faster execution)\\n\")\n",
    "    \n",
    "    quick_config = {\n",
    "        'num_clients': 3,\n",
    "        'num_rounds': 5,\n",
    "        'dataset': 'MNIST',\n",
    "        'attack': 'none'\n",
    "    }\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        print(f\"üìä Testing {strategy.upper()}...\")\n",
    "        \n",
    "        config = quick_config.copy()\n",
    "        config['strategy'] = strategy\n",
    "        \n",
    "        # Run experiment (with shorter timeout)\n",
    "        start_time = time.time()\n",
    "        success = run_basic_experiment(config)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        results[strategy] = {\n",
    "            'success': success,\n",
    "            'duration': end_time - start_time\n",
    "        }\n",
    "        \n",
    "        print(f\"  Result: {'‚úÖ Success' if success else '‚ùå Failed'} ({results[strategy]['duration']:.1f}s)\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"üìà Strategy Comparison Summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    for strategy, result in results.items():\n",
    "        status = \"‚úÖ\" if result['success'] else \"‚ùå\"\n",
    "        print(f\"{strategy:10} {status} ({result['duration']:.1f}s)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment the line below to run the comparison (may take several minutes)\n",
    "# comparison_results = run_strategy_comparison()\n",
    "print(\"üí° Tip: Uncomment the line above to run a strategy comparison experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af8b9a",
   "metadata": {},
   "source": [
    "## üìà Simulated Results Visualization\n",
    "\n",
    "Let's create some example visualizations to show what typical FL results look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example_visualizations():\n",
    "    \"\"\"Create example visualizations of typical FL experiment results.\"\"\"\n",
    "    \n",
    "    # Simulate typical FL training curves\n",
    "    rounds = np.arange(1, 11)\n",
    "    \n",
    "    # Simulate different strategy behaviors\n",
    "    strategies = {\n",
    "        'FedAvg': {\n",
    "            'accuracy': [0.1, 0.45, 0.62, 0.71, 0.77, 0.81, 0.84, 0.86, 0.87, 0.88],\n",
    "            'loss': [2.3, 1.8, 1.4, 1.1, 0.9, 0.75, 0.65, 0.58, 0.53, 0.50]\n",
    "        },\n",
    "        'FedProx': {\n",
    "            'accuracy': [0.1, 0.42, 0.65, 0.74, 0.79, 0.83, 0.85, 0.87, 0.88, 0.89],\n",
    "            'loss': [2.3, 1.9, 1.3, 1.0, 0.85, 0.70, 0.62, 0.55, 0.51, 0.48]\n",
    "        },\n",
    "        'FedAvgM': {\n",
    "            'accuracy': [0.1, 0.48, 0.68, 0.76, 0.81, 0.84, 0.86, 0.88, 0.89, 0.90],\n",
    "            'loss': [2.3, 1.7, 1.2, 0.95, 0.78, 0.68, 0.60, 0.54, 0.49, 0.46]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create plots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax1.set_title('üìä Federated Learning Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "    for strategy, metrics in strategies.items():\n",
    "        ax1.plot(rounds, metrics['accuracy'], marker='o', linewidth=2, label=strategy)\n",
    "    \n",
    "    ax1.set_xlabel('Federation Round')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # Loss plot\n",
    "    ax2.set_title('üìâ Federated Learning Loss Comparison', fontsize=14, fontweight='bold')\n",
    "    for strategy, metrics in strategies.items():\n",
    "        ax2.plot(rounds, metrics['loss'], marker='s', linewidth=2, label=strategy)\n",
    "    \n",
    "    ax2.set_xlabel('Federation Round')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create a summary table\n",
    "    summary_data = []\n",
    "    for strategy, metrics in strategies.items():\n",
    "        summary_data.append({\n",
    "            'Strategy': strategy,\n",
    "            'Final Accuracy': f\"{metrics['accuracy'][-1]:.3f}\",\n",
    "            'Final Loss': f\"{metrics['loss'][-1]:.3f}\",\n",
    "            'Accuracy Improvement': f\"{metrics['accuracy'][-1] - metrics['accuracy'][0]:.3f}\"\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\nüìã Example Results Summary:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nüí° Key Observations:\")\n",
    "    print(\"  ‚Ä¢ FedAvgM shows fastest convergence due to server-side momentum\")\n",
    "    print(\"  ‚Ä¢ FedProx provides stable training with regularization\")\n",
    "    print(\"  ‚Ä¢ FedAvg serves as a reliable baseline\")\n",
    "    print(\"  ‚Ä¢ All strategies show typical FL convergence patterns\")\n",
    "\n",
    "create_example_visualizations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa103e",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "From this notebook, you've learned:\n",
    "\n",
    "### ‚úÖ What You Accomplished\n",
    "1. **Set up and ran** your first federated learning experiment\n",
    "2. **Understood** the FL process flow and key concepts\n",
    "3. **Explored** different ways to run experiments (automated vs manual)\n",
    "4. **Learned** how to monitor and analyze results\n",
    "5. **Compared** different aggregation strategies\n",
    "\n",
    "### üîç Understanding Federated Learning\n",
    "- **Data Privacy**: Raw data never leaves client devices\n",
    "- **Distributed Training**: Each client trains on local data\n",
    "- **Model Aggregation**: Server combines updates without seeing data\n",
    "- **Iterative Process**: Multiple rounds improve global model\n",
    "\n",
    "### üõ†Ô∏è Technical Skills\n",
    "- Running FL experiments with our framework\n",
    "- Configuring different strategies and parameters\n",
    "- Monitoring experiment progress and results\n",
    "- Basic result visualization and analysis\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Ready to dive deeper? Here's what to explore next:\n",
    "\n",
    "1. **[03_Aggregation_Strategies_Deep_Dive.ipynb](./03_Aggregation_Strategies_Deep_Dive.ipynb)** - Detailed exploration of each strategy\n",
    "2. **[04_Attack_Scenarios_and_Security.ipynb](./04_Attack_Scenarios_and_Security.ipynb)** - Security testing with various attacks\n",
    "3. **[05_Comprehensive_Experiments_with_run_extensive_experiments.ipynb](./05_Comprehensive_Experiments_with_run_extensive_experiments.ipynb)** - Large-scale automated experiments\n",
    "\n",
    "## üîß Troubleshooting Tips\n",
    "\n",
    "If you encountered issues:\n",
    "\n",
    "- **Port conflicts**: Make sure ports 8080 is available\n",
    "- **Dependencies**: Ensure all required packages are installed\n",
    "- **Paths**: Verify the framework root path is correct\n",
    "- **Logs**: Check log files for detailed error messages\n",
    "- **Timeout**: Increase timeout values for slower systems\n",
    "\n",
    "**Happy Federated Learning! üéâ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
